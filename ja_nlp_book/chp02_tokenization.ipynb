{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbih/COVID-19/blob/master/ja_nlp_book/chp02_tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97bfd774-eddd-4c54-b76a-378087af568d",
      "metadata": {
        "id": "97bfd774-eddd-4c54-b76a-378087af568d"
      },
      "source": [
        "<a id='top'></a><a name='top'></a>\n",
        "# Chapter 2: Tokenization, Morphological Analysis, and Dependency Parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c437ede2-3caf-4c98-8031-a2e81f4fb234",
      "metadata": {
        "id": "c437ede2-3caf-4c98-8031-a2e81f4fb234"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/gbih/nlp/blob/main/ja_nlp_book/chp02_tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e63e5931-27fa-49b2-a404-90be1d506fe3",
      "metadata": {
        "id": "e63e5931-27fa-49b2-a404-90be1d506fe3"
      },
      "source": [
        "* [2.0 Imports and Setup](#2.0)\n",
        "* [2.1 An Introduction to fugashi](#2.1)\n",
        "    - [2.1.1 Setup](#2.1.1)\n",
        "    - [2.1.2 Morphological Analysis Mini Project: Automatic Fuseji](#2.1.2)\n",
        "    - [2.1.3 Censoring Unknown Words](#2.1.3)\n",
        "    - [2.1.4 Use Readings to Censor only Part of Words](#2.1.4)\n",
        "* [2.2 Improving Tokenization Quality with a User Dictionary](#2.2)\n",
        "    - [2.2.1 Why Make a Custom Tokenizer Dictionary?](#2.2.1)\n",
        "    - [2.2.2 Generating a MeCab User Dictionary](#2.2.2)\n",
        "    - [2.2.3 Creating a SudachiPy User Dictionary](#2.2.3)\n",
        "    - [2.2.4 Sourcing Your Own Data](#2.2.4)\n",
        "    - [2.2.5 Sourcing Internet Data](#2.2.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e41cd62-2e6b-417c-9538-baa88282dd7c",
      "metadata": {
        "id": "6e41cd62-2e6b-417c-9538-baa88282dd7c"
      },
      "source": [
        "---\n",
        "<a name='2.0'></a><a id='2.0'></a>\n",
        "# 2.0 Imports and Setup\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d0e7a591-5585-47c6-aa31-200bf84b584a",
      "metadata": {
        "id": "d0e7a591-5585-47c6-aa31-200bf84b584a"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "data_root = Path(\"chp02\")\n",
        "req_file = data_root / \"requirements_2.txt\"\n",
        "\n",
        "if not data_root.is_dir():\n",
        "    data_root.mkdir()\n",
        "else:\n",
        "    print(f\"{data_root} exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cf6813c5-94c9-4600-a3f2-86e732f345c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf6813c5-94c9-4600-a3f2-86e732f345c2",
        "outputId": "08a758df-c5aa-4104-899d-3b9f946f4574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing chp02/requirements_2.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile {req_file}\n",
        "fugashi[unidic]==1.2.1\n",
        "watermark==2.3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bb52e1d7-d29b-4ede-8875-de63c06d7b3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb52e1d7-d29b-4ede-8875-de63c06d7b3d",
        "outputId": "d9cbd34b-a356-4074-862f-c70171206e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing packages\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.9/599.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "download url: https://cotonoha-dic.s3-ap-northeast-1.amazonaws.com/unidic-3.1.0.zip\n",
            "Dictionary version: 3.1.0+2021-08-31\n",
            "Downloading UniDic v3.1.0+2021-08-31...\n",
            "unidic-3.1.0.zip: 100% 526M/526M [00:15<00:00, 33.8MB/s]\n",
            "Finished download.\n",
            "Downloaded UniDic v3.1.0+2021-08-31 to /usr/local/lib/python3.10/dist-packages/unidic/dicdir\n",
            "Packages installed.\n"
          ]
        }
      ],
      "source": [
        "# unidic==1.1.0\n",
        "import sys\n",
        "import os\n",
        "check1 = ('google.colab' in sys.modules)\n",
        "check2 = (os.environ.get('CLOUDSDK_CONFIG')=='/content/.config')\n",
        "IS_COLAB = True if (check1 or check2) else False\n",
        "\n",
        "if IS_COLAB:\n",
        "    print(\"Installing packages\")\n",
        "    !pip install --quiet -r {req_file}\n",
        "    !python -m unidic download\n",
        "    print(\"Packages installed.\")\n",
        "else:\n",
        "    print(\"Running locally.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "98ab493c-8720-4ddb-9a4f-0694bbb8485f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98ab493c-8720-4ddb-9a4f-0694bbb8485f",
        "outputId": "d3a93519-c1b8-43e7-8003-0ee083168ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 6.1.85+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "fugashi: 1.2.1\n",
            "sys    : 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Standard Library imports\n",
        "from importlib.metadata import version\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Third-party imports\n",
        "import fugashi\n",
        "from fugashi import Tagger\n",
        "from random import sample\n",
        "from watermark import watermark\n",
        "\n",
        "def HR():\n",
        "    print(\"-\"*50)\n",
        "\n",
        "# Examine all imported packages\n",
        "print(watermark(iversions=True, globals_=globals(),python=True, machine=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "73f223b7-5ade-4245-9c9e-b2d6102bfd2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73f223b7-5ade-4245-9c9e-b2d6102bfd2d",
        "outputId": "82657b22-81a6-4f55-beae-97d767f653c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported specified packages.\n"
          ]
        }
      ],
      "source": [
        "assert version('fugashi') == '1.2.1'\n",
        "\n",
        "print(\"Successfully imported specified packages.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bab356d-0223-4e1f-8ab4-df061bfd669b",
      "metadata": {
        "id": "5bab356d-0223-4e1f-8ab4-df061bfd669b"
      },
      "source": [
        "---\n",
        "<a name='2.1'></a><a id='2.1'></a>\n",
        "# 2.1 An Introduction to fugashi\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Adapted from [2.1-fugashi-fuseji.ipynb](https://github.com/octanove/janlpbook-code/blob/main/en/2.1-fugashi-fuseji.ipynb) by Paul O'Leary McCann and Masato Hagiwara\n",
        "\n",
        "\n",
        "fugashi provides four different dictionaries pre‐packaged:\n",
        "\n",
        "1. JumanDic\n",
        "2. UniDic\n",
        "3. unidic‐lite\n",
        "4. IPAdic\n",
        "\n",
        "**Reference**\n",
        "\n",
        "https://github.com/polm/fugashi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "663587c6-7c6a-4249-9b39-0ed5e391e5c6",
      "metadata": {
        "id": "663587c6-7c6a-4249-9b39-0ed5e391e5c6"
      },
      "source": [
        "<a name='2.1.1'></a><a id='2.1.1'></a>\n",
        "## 2.1.1 Setup\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Assuming installation above. Test via the command-line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "db354171-1a00-47f8-b300-52e383e8b861",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db354171-1a00-47f8-b300-52e383e8b861",
        "outputId": "b55a1e0b-59d4-4099-996a-810de0cd098b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "毎年 東 麻布 で は かかし祭り が 開催 さ れ ます\n"
          ]
        }
      ],
      "source": [
        "!echo \"毎年東麻布ではかかし祭りが開催されます\" | fugashi -O wakati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "16754f7b-5ccb-4d3c-acd5-3ec0bd53f444",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16754f7b-5ccb-4d3c-acd5-3ec0bd53f444",
        "outputId": "f64bd1f0-588e-4478-bd70-a1a26913d9d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[形態, 素, 解析, を, やっ, て, み, た]\n",
            "--------------------------------------------------\n",
            "形態\t形態\tケイタイ\n",
            "素\t素\tソ\n",
            "解析\t解析\tカイセキ\n",
            "を\tを\tヲ\n",
            "やっ\t遣る\tヤッ\n",
            "て\tて\tテ\n",
            "み\t見る\tミ\n",
            "た\tた\tタ\n"
          ]
        }
      ],
      "source": [
        "tagger = Tagger()\n",
        "\n",
        "text = \"形態素解析をやってみた\"\n",
        "words = tagger(text)\n",
        "print(words)\n",
        "HR()\n",
        "\n",
        "for word in words:\n",
        "    print(word.surface, word.feature.lemma, word.feature.kana, sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cabed6a7-b81c-4e2f-bb4a-a0b9be8d1a77",
      "metadata": {
        "id": "cabed6a7-b81c-4e2f-bb4a-a0b9be8d1a77"
      },
      "source": [
        "<a name='2.1.2'></a><a id='2.1.2'></a>\n",
        "## 2.1.2 Morphological Analysis Mini Project: Automatic Fuseji\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f91c2d1e-ddcf-41c9-902d-9f5754dfd9fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f91c2d1e-ddcf-41c9-902d-9f5754dfd9fa",
        "outputId": "eac1205e-301f-43c7-94a1-d80e76ec1f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "犯人は◯◯\n",
            "◯◯タワーの高さは333m\n"
          ]
        }
      ],
      "source": [
        "tagger = Tagger()\n",
        "\n",
        "def fuseji_node(text, ratio=1.0):\n",
        "    \"\"\"This function will take a node from tokenization and actually replace parts of it with filler characters.\"\"\"\n",
        "    ll = len(text)\n",
        "    idxs = sample(range(ll), max(1, int(ratio * ll)))\n",
        "    out = []\n",
        "    for ii, cc in enumerate(text):\n",
        "        out.append(\"◯\" if ii in idxs else cc)\n",
        "    return \"\".join(out)\n",
        "\n",
        "\n",
        "def fuseji_text(text, ratio=1.0):\n",
        "    \"\"\"Given an input string, apply fuseji. \"\"\"\n",
        "    out = []\n",
        "    for node in tagger(text):\n",
        "        # Normal Japanese text doesn't use white space, but this is necessary\n",
        "        # if you include latin text, for example.\n",
        "        out.append(node.white_space)\n",
        "        if node.feature.pos2 != \"固有名詞\":\n",
        "            out.append(node.surface)\n",
        "        else:\n",
        "            out.append(fuseji_node(node.surface))\n",
        "    return \"\".join(out)\n",
        "\n",
        "print(fuseji_text(\"犯人はヤス\"))\n",
        "print(fuseji_text(\"東京タワーの高さは333m\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "000d4ced-7670-44c0-998b-9b81a737e965",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "000d4ced-7670-44c0-998b-9b81a737e965",
        "outputId": "54e7eac7-b4e5-4003-fbb2-904019771ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "毎年\t名詞,普通名詞,副詞可能,,,,マイトシ,毎年,毎年,マイトシ,毎年,マイトシ,混,\"\",\"\",\"\",\"\",\"\",\"\",体,マイトシ,マイトシ,マイトシ,マイトシ,\"0\",\"C2\",\"\",9737558477120000,35425\n",
            "東\t名詞,普通名詞,一般,,,,ヒガシ,東,東,ヒガシ,東,ヒガシ,和,\"\",\"\",\"\",\"\",\"\",\"\",体,ヒガシ,ヒガシ,ヒガシ,ヒガシ,\"0,3\",\"C2\",\"\",8566303715631616,31164\n",
            "麻布\t名詞,固有名詞,地名,一般,,,アザブ,アザブ,麻布,アザブ,麻布,アザブ,固,\"\",\"\",\"\",\"\",\"\",\"\",地名,アザブ,アザブ,アザブ,アザブ,\"0\",\"\",\"\",163560978260480,595\n",
            "で\t助詞,格助詞,,,,,デ,で,で,デ,で,デ,和,\"\",\"\",\"\",\"\",\"\",\"\",格助,デ,デ,デ,デ,\"\",\"動詞%F2@0,名詞%F1\",\"\",7014343053025792,25518\n",
            "は\t助詞,係助詞,,,,,ハ,は,は,ワ,は,ワ,和,\"\",\"\",\"\",\"\",\"\",\"\",係助,ハ,ハ,ハ,ハ,\"\",\"動詞%F2@0,名詞%F1,形容詞%F2@-1\",\"\",8059703733133824,29321\n",
            "かかし祭り\t名詞,普通名詞,一般,,,,カカシマツリ,案山子祭り,かかし祭り,カカシマツリ,かかし祭り,カカシマツリ,和,\"\",\"\",\"\",\"\",\"\",\"\",体,カカシマツリ,カカシマツリ,カカシマツリ,カカシマツリ,\"4\",\"C1\",\"\",76478189161030144,278226\n",
            "が\t助詞,格助詞,,,,,ガ,が,が,ガ,が,ガ,和,\"\",\"\",\"\",\"\",\"\",\"\",格助,ガ,ガ,ガ,ガ,\"\",\"動詞%F2@0,名詞%F1\",\"\",2168520431510016,7889\n",
            "開催\t名詞,普通名詞,サ変可能,,,,カイサイ,開催,開催,カイサイ,開催,カイサイ,漢,\"\",\"\",\"\",\"\",\"\",\"\",体,カイサイ,カイサイ,カイサイ,カイサイ,\"0\",\"C2\",\"\",65579280150700544,238576\n",
            "さ\t動詞,非自立可能,,,サ行変格,未然形-サ,スル,為る,さ,サ,する,スル,和,\"\",\"\",\"\",\"\",\"\",\"\",用,サ,スル,サ,スル,\"0\",\"C5\",\"\",5370298291593794,19537\n",
            "れ\t助動詞,,,,助動詞-レル,連用形-一般,レル,れる,れ,レ,れる,レル,和,\"\",\"\",\"\",\"\",\"\",\"\",助動,レ,レル,レ,レル,\"\",\"動詞%F3@1\",\"M4@1\",11198809430434433,40741\n",
            "ます\t助動詞,,,,助動詞-マス,終止形-一般,マス,ます,ます,マス,ます,マス,和,\"\",\"\",\"\",\"\",\"\",\"\",助動,マス,マス,マス,マス,\"\",\"動詞%F4@1\",\"\",9812325267808939,35697\n",
            "EOS\n"
          ]
        }
      ],
      "source": [
        "!echo \"毎年東麻布ではかかし祭りが開催されます\" | fugashi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8152674f-9f06-4488-acd2-8272e8eeb70c",
      "metadata": {
        "id": "8152674f-9f06-4488-acd2-8272e8eeb70c"
      },
      "source": [
        "<a name='2.1.3'></a><a id='2.1.3'></a>\n",
        "## 2.1.3 Censoring Unknown Words\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ec7b03ed-610c-4faa-b5fd-7f28b1dbbeb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec7b03ed-610c-4faa-b5fd-7f28b1dbbeb8",
        "outputId": "f15ba1e2-e2eb-4f45-f598-5617f34b38db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "犯人は◯◯\n",
            "魔法の言葉は◯◯◯◯◯\n",
            "『さかしま』（仏: ◯ ◯◯◯◯◯◯◯）は、◯◯◯◯の作家◯◯◯◯＝◯◯◯・◯◯◯◯◯◯による小説\n",
            "◯◯爆発で最初に解体する爆弾はみかんの形をしている\n"
          ]
        }
      ],
      "source": [
        "def should_hide(node):\n",
        "    \"\"\"Check if this node should be hidden or not. \"\"\"\n",
        "    if node.is_unk:\n",
        "        return True\n",
        "    ff = node.feature\n",
        "    if ff.pos1 == \"名詞\" and ff.pos2 == \"固有名詞\":\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def fuseji_text(text, ratio=1.0):\n",
        "    \"\"\"Given an input string, apply fuseji. \"\"\"\n",
        "    out = []\n",
        "    for node in tagger(text):\n",
        "        out.append(node.white_space)\n",
        "        word = fuseji_node(node.surface) if should_hide(node) else node.surface\n",
        "        out.append(word)\n",
        "    return \"\".join(out)\n",
        "\n",
        "texts = [\n",
        "    \"犯人はヤス\",\n",
        "    \"魔法の言葉はヒラケゴマ\",\n",
        "    \"『さかしま』（仏: À rebours）は、フランスの作家ジョリス＝カルル・ユイスマンスによる小説\",\n",
        "    \"鈴木爆発で最初に解体する爆弾はみかんの形をしている\",\n",
        "]\n",
        "\n",
        "for text in texts:\n",
        "    print(fuseji_text(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eab0f019-2c03-45aa-9ea9-b3574e3f5809",
      "metadata": {
        "id": "eab0f019-2c03-45aa-9ea9-b3574e3f5809"
      },
      "source": [
        "<a name='2.1.4'></a><a id='2.1.4'></a>\n",
        "## 2.1.4 Use Readings to Censor only Part of Words\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4d40eca7-9b59-41c4-81ba-f91f7e5dccd8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d40eca7-9b59-41c4-81ba-f91f7e5dccd8",
        "outputId": "4194f58e-8766-4b21-f1ad-afaf6ec5ef05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "黒幕の正体はガーランド\n"
          ]
        }
      ],
      "source": [
        "def fuseji_text(text, ratio=1.0):\n",
        "    \"\"\"Given an input string, apply fuseji. \"\"\"\n",
        "    out = []\n",
        "    for node in tagger(text):\n",
        "        out.append(node.white_space)\n",
        "        node_text = node.surface if node.is_unk else node.feature.kana\n",
        "        word = fuseji_node(node_text, ratio=0.5) if should_hide(node) else node.surface\n",
        "        out.append(word)\n",
        "    return \"\".join(out)\n",
        "\n",
        "texts = [\n",
        "    \"黒幕の正体はガーランド\",\n",
        "]\n",
        "\n",
        "for text in texts:\n",
        "    print(fuseji_text(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea2e1a03-7b1f-4558-ace4-9e455ea74920",
      "metadata": {
        "id": "ea2e1a03-7b1f-4558-ace4-9e455ea74920"
      },
      "source": [
        "---\n",
        "<a name='2.2'></a><a id='2.2'></a>\n",
        "# 2.2 Improving Tokenization Quality with a User Dictionary\n",
        "<a href=\"#top\">[back to top]</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a31c6264-2702-41e2-b67e-26d8bfbc9899",
      "metadata": {
        "id": "a31c6264-2702-41e2-b67e-26d8bfbc9899"
      },
      "source": [
        "<a name='2.2.1'></a><a id='2.2.1'></a>\n",
        "## 2.2.1 Why Make a Custom Tokenizer Dictionary?\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "No source code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f99a3b34-e320-46aa-a24d-18310265bab4",
      "metadata": {
        "id": "f99a3b34-e320-46aa-a24d-18310265bab4"
      },
      "source": [
        "<a name='2.2.2'></a><a id='2.2.2'></a>\n",
        "## 2.2.2 Generating a MeCab User Dictionary\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6114797b-7254-41c1-b55f-a1cb73751a25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6114797b-7254-41c1-b55f-a1cb73751a25",
        "outputId": "2e6c3a2f-23d5-4ccb-9613-4ab0c42cad02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ドロッチェ,,,100,名 詞,固 有 名 詞,一 般,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*\n",
            "デデデ,,,100,名 詞,固 有 名 詞,一 般,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*\n",
            "水しょう,,,100,名 詞,固 有 名 詞,一 般,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*\n"
          ]
        }
      ],
      "source": [
        "# The Minimal Approach\n",
        "pos = \"名 詞,固 有 名 詞,一 般,*\".split(\",\")\n",
        "words = [\"ドロッチェ\", \"デデデ\", \"水しょう\"]\n",
        "empty = \"*\"\n",
        "\n",
        "for word in words:\n",
        "# pos is four fields, so (26 ‐ 4) == 22\n",
        "    entry = [word, \"\", \"\", \"100\"] + pos + (22 * [empty])\n",
        "    print(\",\".join(entry))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Thorough Approach"
      ],
      "metadata": {
        "id": "u-H7uya2Lz7a"
      },
      "id": "u-H7uya2Lz7a"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dcba540b-f736-43dc-9530-8ff06f46c30f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcba540b-f736-43dc-9530-8ff06f46c30f",
        "outputId": "fdd2d664-373d-43d2-c92c-262547a7c87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "一般,*,*,*,*,*,*,水 晶,*,ス イ シ ョ ー,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*\n"
          ]
        }
      ],
      "source": [
        "from fugashi import UnidicFeatures26\n",
        "\n",
        "# field names come from fugashi\n",
        "words = [(\"水 し ょ う\", {\"pron\": \"ス イ シ ョ ー\", \"lemma\": \"水 晶\"})]\n",
        "fields = UnidicFeatures26._fields\n",
        "\n",
        "for word, data in words:\n",
        "    entry = {}\n",
        "    for field in fields:\n",
        "        entry[field] = data.get(field, \"*\")\n",
        "\n",
        "    # assume pos is hard‐coded\n",
        "    entry[\"pos1\"] = \"名詞\"\n",
        "    entry[\"pos1\"] = \"固有名詞\"\n",
        "    entry[\"pos1\"] = \"一般\"\n",
        "    print(\",\".join(entry.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Extra Approach\n",
        "\n",
        "To-do\n",
        "\n",
        "If we need to specify the pathway to the system dictionary, we can use `unidic.DICDIR`"
      ],
      "metadata": {
        "id": "8J_b0dWLLxIf"
      },
      "id": "8J_b0dWLLxIf"
    },
    {
      "cell_type": "markdown",
      "id": "59dd17c5-faf0-4591-b0f7-ae3387fe386c",
      "metadata": {
        "id": "59dd17c5-faf0-4591-b0f7-ae3387fe386c"
      },
      "source": [
        "<a name='2.2.3'></a><a id='2.2.3'></a>\n",
        "## 2.2.3 Creating a SudachiPy User Dictionary\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "No source code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e91f5e90-b56b-4f94-8c86-2ad181fcc741",
      "metadata": {
        "id": "e91f5e90-b56b-4f94-8c86-2ad181fcc741"
      },
      "source": [
        "<a name='2.2.4'></a><a id='2.2.4'></a>\n",
        "## 2.2.4 Sourcing Your Own Data\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "No source code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd0c7399-ad18-4f4c-b94a-7f79b8196907",
      "metadata": {
        "id": "cd0c7399-ad18-4f4c-b94a-7f79b8196907"
      },
      "source": [
        "<a name='2.2.5'></a><a id='2.2.5'></a>\n",
        "## 2.2.5 Sourcing Internet Data\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "No source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5079a931-a235-47ea-8096-d127efd64ab3",
      "metadata": {
        "id": "5079a931-a235-47ea-8096-d127efd64ab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85b0c8a-e5f8-4679-d170-494438d2edfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "麩 (フ)\n",
            "菓子 (カシ)\n",
            "は (ハ)\n",
            "、 (*)\n",
            "麩 (フスマ)\n",
            "を (ヲ)\n",
            "主材 (シュザイ)\n",
            "料 (リョウ)\n",
            "と (ト)\n",
            "し (シ)\n",
            "た (タ)\n",
            "日本 (ニッポン)\n",
            "の (ノ)\n",
            "菓子 (カシ)\n",
            "。 (*)\n"
          ]
        }
      ],
      "source": [
        "import fugashi\n",
        "\n",
        "tagger = fugashi.Tagger()\n",
        "text = \"麩菓子は、麩を主材料とした日本の菓子。\"\n",
        "\n",
        "for word in tagger(text):\n",
        "    print(f\"{word.surface} ({word.feature.kana})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-S_ng9q0KCJ2"
      },
      "id": "-S_ng9q0KCJ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fugashi\n",
        "\n",
        "tagger = fugashi.Tagger()\n",
        "text = \"麩菓子は、麩を主材料とした日本の菓子。\"\n",
        "\n",
        "words = [word.surface for word in tagger(text)]\n",
        "print(*words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7HM9QXoJhbA",
        "outputId": "87f311b5-367c-43b5-dc65-36bf6257845c"
      },
      "id": "m7HM9QXoJhbA",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "麩 菓子 は 、 麩 を 主材 料 と し た 日本 の 菓子 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tagger(text):\n",
        "    print(word.surface, word.feature.lemma, sep=\"\\t\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GJZJGZAJlAA",
        "outputId": "39599807-4fc7-4120-a3e7-43ad2948fbf2"
      },
      "id": "_GJZJGZAJlAA",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "麩\t麩\n",
            "菓子\t菓子\n",
            "は\tは\n",
            "、\t、\n",
            "麩\t麩\n",
            "を\tを\n",
            "主材\t主材\n",
            "料\t料\n",
            "と\tと\n",
            "し\t為る\n",
            "た\tた\n",
            "日本\t日本\n",
            "の\tの\n",
            "菓子\t菓子\n",
            "。\t。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fugashi\n",
        "import re\n",
        "\n",
        "def get_furigana(text):\n",
        "    tagger = fugashi.Tagger()\n",
        "    result = []\n",
        "\n",
        "    for word in tagger(text):\n",
        "        surface = word.surface\n",
        "        reading = word.feature.kana\n",
        "\n",
        "        if re.search(r'[\\u4e00-\\u9faf]', surface):  # Check if the word contains kanji\n",
        "            result.append(f\"{surface}({reading})\")\n",
        "        else:\n",
        "            result.append(surface)\n",
        "\n",
        "    return ''.join(result)\n",
        "\n",
        "# Example usage\n",
        "text = \"麩菓子は、麩を主材料とした日本の菓子。\"\n",
        "print(get_furigana(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd4_9XG5KDdu",
        "outputId": "67af2f50-ca03-4978-b52c-259774c76836"
      },
      "id": "pd4_9XG5KDdu",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "麩(フ)菓子(カシ)は、麩(フスマ)を主材(シュザイ)料(リョウ)とした日本(ニッポン)の菓子(カシ)。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jaconv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBkZ66w9KjN1",
        "outputId": "c85a346b-3f3f-485a-af06-3a48cff53943"
      },
      "id": "MBkZ66w9KjN1",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jaconv\n",
            "  Downloading jaconv-0.4.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: jaconv\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.4.0-py3-none-any.whl size=18229 sha256=8cf9d4309d1b538b6f2428ad8172dba2fd84ecaacf2011a4aac5bc4281fc1324\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/95/99/94e8d7545125181756857f6b1fc085ed4e0811ad9be7321af7\n",
            "Successfully built jaconv\n",
            "Installing collected packages: jaconv\n",
            "Successfully installed jaconv-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install jaconv\n",
        "import fugashi\n",
        "from jaconv import kata2hira\n",
        "\n",
        "def apply_hiragana_furigana(text):\n",
        "    tagger = fugashi.Tagger()\n",
        "    result = []\n",
        "\n",
        "    for word in tagger(text):\n",
        "        surface = word.surface\n",
        "        reading = kata2hira(word.feature.kana)  # Convert katakana to hiragana\n",
        "\n",
        "        if any('\\u4e00' <= char <= '\\u9faf' for char in surface):  # Check if word contains kanji\n",
        "            furigana_word = ''\n",
        "            for char in surface:\n",
        "                if '\\u4e00' <= char <= '\\u9faf':  # If character is kanji\n",
        "                    furigana_word += f\"{char}({reading})\"\n",
        "                else:\n",
        "                    furigana_word += char\n",
        "            result.append(furigana_word)\n",
        "        else:\n",
        "            result.append(surface)\n",
        "\n",
        "    return ''.join(result)\n",
        "\n",
        "# Example usage\n",
        "text = \"麩菓子は、麩を主材料とした日本の菓子。\"\n",
        "print(apply_hiragana_furigana(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_4xc-pCKg3O",
        "outputId": "8c59ee95-95ec-4de5-d1ef-fd9986820d06"
      },
      "id": "q_4xc-pCKg3O",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "麩(ふ)菓(かし)子(かし)は、麩(ふすま)を主(しゅざい)材(しゅざい)料(りょう)とした日(にっぽん)本(にっぽん)の菓(かし)子(かし)。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fugashi\n",
        "from jaconv import kata2hira\n",
        "\n",
        "def apply_word_furigana(text):\n",
        "    tagger = fugashi.Tagger()\n",
        "    result = []\n",
        "\n",
        "    for word in tagger(text):\n",
        "        surface = word.surface\n",
        "        reading = kata2hira(word.feature.kana)  # Convert katakana to hiragana\n",
        "\n",
        "        if any('\\u4e00' <= char <= '\\u9faf' for char in surface):  # Check if word contains kanji\n",
        "            if surface != reading:  # Only add furigana if it's different from the surface form\n",
        "                result.append(f\"{surface}({reading})\")\n",
        "            else:\n",
        "                result.append(surface)\n",
        "        else:\n",
        "            result.append(surface)\n",
        "\n",
        "    return ''.join(result)\n",
        "\n",
        "# Example usage\n",
        "text = \"その１つは⸺\"\n",
        "# print(text)\n",
        "print(apply_word_furigana(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "hv4CnqhvLOWO",
        "outputId": "87850f56-5de9-455a-e713-2babf22641c8"
      },
      "id": "hv4CnqhvLOWO",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'translate'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-40a8efa92ad4>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"その１つは⸺\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# print(text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_word_furigana\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-40a8efa92ad4>\u001b[0m in \u001b[0;36mapply_word_furigana\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msurface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mreading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkata2hira\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkana\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert katakana to hiragana\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\u4e00'\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;34m'\\u9faf'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Check if word contains kanji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jaconv/jaconv.py\u001b[0m in \u001b[0;36mkata2hira\u001b[0;34m(text, ignore)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mまみさン\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK2H_TABLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jaconv/jaconv.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(text, ignore, conv_map)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0m_conv_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_exclude_ignorechar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_conv_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jaconv/jaconv.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(text, conv_map)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'translate'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "麩菓子は、麩を主材料とした日本の菓子。\n",
        "\n",
        "麩[ふ]\n",
        "菓子[かし]\n",
        "は、麩[ふすま]\n",
        "を主材[しゅざい]\n",
        "料[りょう]\n",
        "とした日本[にっぽん]\n",
        "の菓子[かし]。"
      ],
      "metadata": {
        "id": "Cb2ZuAKvNOGh"
      },
      "id": "Cb2ZuAKvNOGh"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HCRI5ef-SfTz"
      },
      "id": "HCRI5ef-SfTz"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ORot6G7aSfWp"
      },
      "id": "ORot6G7aSfWp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The error you're encountering is due to word.feature.kana returning None for certain characters, specifically non-Japanese characters or symbols. In this case, the em dash (⸺) is causing the issue. We need to handle cases where word.feature.kana might be None. Here's a modified version of the code that addresses this problem:\n",
        "\n",
        "The key changes are:\n",
        "\n",
        "    We check if reading is None before attempting to convert it to hiragana.\n",
        "    If reading is None, we simply append the surface form of the word.\n",
        "\n",
        "This modification should handle cases where word.feature.kana returns None, which can happen for non-Japanese characters, numbers, or certain symbols. With these changes, the script should run without errors and produce output like this:"
      ],
      "metadata": {
        "id": "WJSzceMySfaU"
      },
      "id": "WJSzceMySfaU"
    },
    {
      "cell_type": "code",
      "source": [
        "import fugashi\n",
        "from jaconv import kata2hira\n",
        "\n",
        "def apply_word_furigana(text):\n",
        "    tagger = fugashi.Tagger()\n",
        "    result = []\n",
        "\n",
        "    for word in tagger(text):\n",
        "        surface = word.surface\n",
        "        reading = word.feature.kana\n",
        "\n",
        "        if reading is not None:\n",
        "            reading = kata2hira(reading)  # Convert katakana to hiragana\n",
        "\n",
        "            if any('\\u4e00' <= char <= '\\u9faf' for char in surface):  # Check if word contains kanji\n",
        "                if surface != reading:  # Only add furigana if it's different from the surface form\n",
        "                    result.append(f\"{surface}({reading})\")\n",
        "                else:\n",
        "                    result.append(surface)\n",
        "            else:\n",
        "                result.append(surface)\n",
        "        else:\n",
        "            result.append(surface)  # Append surface form if no reading is available\n",
        "\n",
        "    return ''.join(result)\n",
        "\n",
        "# Example usage\n",
        "text = \"知識も能力もです\"\n",
        "print(apply_word_furigana(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7CA8KUiNQRt",
        "outputId": "5195308f-d873-4509-8158-f2da8eacdd24"
      },
      "id": "a7CA8KUiNQRt",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "知識(ちしき)も能力(のうりょく)もです\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y1GeQ0aOSYiw"
      },
      "id": "y1GeQ0aOSYiw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}